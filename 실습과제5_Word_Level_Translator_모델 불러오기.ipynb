{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "492fd0b1",
   "metadata": {},
   "source": [
    "# Word-Level 번역기 만들기(Neural Machine Translation (seq2seq) Tutorial)\n",
    "\n",
    ">- __전공 : 컴퓨터전자시스템 공학부__\n",
    ">- __학번:  201600765__\n",
    ">- __이름 : 김주원__\n",
    "\n",
    "- model.load()를 이용하여 학습된 모델을 불러와서 테스트를 진행해본 실습 파일입니다. 아래와 같이 load_model을 통해 학습시간, 모델 설계 및 재설계 시간을 줄일 수 있습니다.1,2번에 대한 답안은 \"실습과제5_Word_Level_Translator_모델_불러오기_1,2번_답안_201600765_김주원.pdf\"파일을 참고해주시면 됩니다. 감사합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec16d4",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 전처리\n",
    "- 필요한 도구들을 import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1ac368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "import urllib3\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c31721",
   "metadata": {},
   "source": [
    "#### 데이터를 로드\n",
    "- fra.txt 데이터 구조 : 왼쪽의 영어 문장과 오른쪽의 프랑스어 문장 사이에 탭으로 구분되는 구조."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd09c00d",
   "metadata": {},
   "source": [
    "- 이번 챕터에서는 총 33,000개의 샘플을 사용할 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f282b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 33000\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:\n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a9c754",
   "metadata": {},
   "source": [
    "- 전처리 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4841c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2a9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2c349",
   "metadata": {},
   "source": [
    "- 구현한 전처리 함수들을 임의의 문장을 입력으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c89791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have you had dinner ?\n",
      "b'avez vous deja dine ?'\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "print(preprocess_sentence(en_sent))\n",
    "print(preprocess_sentence(fr_sent).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cd012b",
   "metadata": {},
   "source": [
    "#### 모든 전처리를 수행하는 함수 구현\n",
    "- 전체 데이터에서 33,000개의 샘플불러옴. \n",
    "- 훈련 과정에서 교사 강요(Teacher Forcing)을 사용할 예정=> 훈련 시 사용할 디코더의 입력 시퀀스와 실제값에 해당되는 출력 시퀀스를 따로 분리하여 저장\n",
    "- 입력 시퀀스에는 시작을 의미하는 토큰인 `<sos>`를 추가 \n",
    "- 출력 시퀀스에는 종료를 의미하는 토큰인`<eos>`를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20cb90fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\", encoding=\"utf-8\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line_input)\n",
    "            decoder_input.append(tar_line_input)\n",
    "            decoder_target.append(tar_line_target)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99028d",
   "metadata": {},
   "source": [
    "- 인코더의 입력, 디코더의 입력, 디코더의 실제값을 상위 5개 샘플만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d31c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.']]\n",
      "[['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print(sents_en_in[:5])\n",
    "print(sents_fra_in[:5])\n",
    "print(sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f376c",
   "metadata": {},
   "source": [
    "- 케라스 토크나이저를 통해 단어 집합을 생성하고, 텍스트 시퀀스를 정수 시퀀스로 변환하는 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56901722",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7893b1",
   "metadata": {},
   "source": [
    "- 패딩을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c02c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cef44a",
   "metadata": {},
   "source": [
    "- 데이터의 크기(shape)를 확인\n",
    "- 샘플은 총 33,000개 존재하며 영어 문장의 길이는 8, 프랑스어 문장의 길이 16\n",
    "- 단어 집합의 크기를 정의\n",
    "- 단어 집합의 크기는 각각 4,647개와 8,022개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b995c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4606, 프랑스어 단어 집합의 크기 : 8107\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa225c8",
   "metadata": {},
   "source": [
    "- 단어로부터 정수를 얻는 딕셔너리 구현\n",
    "- 정수로부터 단어를 얻는 딕셔너리 구현 \n",
    "  - 훈련을 마치고 예측 과정과 실제값과 결과를 비교하는 경우에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef894d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용\n",
    "\n",
    "tar_to_index = tokenizer_fra.word_index # 훈련 후 예측 과정에서 사용\n",
    "index_to_tar = tokenizer_fra.index_word # 훈련 후 결과 비교할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d833d",
   "metadata": {},
   "source": [
    "- 테스트 데이터를 분리하기 전에, 적절한 분포를 갖도록 데이터를 섞어주는 과정을 진행\n",
    "  - 이를 위해서 우선 순서가 섞인 정수 시퀀스 리스트 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a822f382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32250 16672 23036 ...     1    54 21477]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7fa521",
   "metadata": {},
   "source": [
    "- 데이터셋의 순서로 지정, 샘플들이 기존 순서와 다른 순서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2167d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dca8a7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,  20,  44, 126,   1,   0,   0,   0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38642020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  19,  34,  57, 448,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551f5c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 19,  34,  57, 448,   1,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target[30997]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f599f",
   "metadata": {},
   "source": [
    "- 테스트 데이터 : 33,000개의 10%에 해당되는 3,300개의 데이터를 테스트 데이터로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a861308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(33000*0.1)\n",
    "print(n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9394753",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d26527",
   "metadata": {},
   "source": [
    "- 훈련 데이터와 테스트 데이터의 크기(shape)를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05ded949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29700, 8)\n",
      "(29700, 16)\n",
      "(29700, 16)\n",
      "(3300, 8)\n",
      "(3300, 16)\n",
      "(3300, 16)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2776e543",
   "metadata": {},
   "source": [
    "## 2. 기계번역어 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc8afeb",
   "metadata": {},
   "source": [
    "- load_model함수를 통해 \"Word_level_translator.h5\"학습모델 파일 로드해서 코드 한줄로 학습데이터를 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de315e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"Word_level_translator.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eabc00e",
   "metadata": {},
   "source": [
    "- 모델의 파라미터를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "421881f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     230300      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     405350      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 50)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 50)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50), (None,  20200       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8107)   413457      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,089,507\n",
      "Trainable params: 1,089,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f2031",
   "metadata": {},
   "source": [
    "## 3. seq2seq 기계 번역기 동작시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25647a",
   "metadata": {},
   "source": [
    "- seq2seq는 훈련 과정과 테스트 과정에서의 동작 방식이 다름\n",
    "  -  따라서 테스트 과정을 위해 재설계된 모델을 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e0d2e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder_model = load_model(\"encoder_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88076f",
   "metadata": {},
   "source": [
    "- 디코더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "869b931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "decoder_model = load_model(\"decoder_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26305acd",
   "metadata": {},
   "source": [
    "- 테스트 과정에서의 동작을 위한 decode_sequence 함수 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efda8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fe30b",
   "metadata": {},
   "source": [
    "- 결과 확인을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34a2fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    sentence = ''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            sentence = sentence + index_to_src[i]+' '\n",
    "    return sentence\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    sentence =''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
    "            sentence = sentence + index_to_tar[i] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87f4c5",
   "metadata": {},
   "source": [
    "#### 학번 맨 뒤 2자리를 이용한 인덱스 리스트 생성\n",
    "- 201600765가 학번이므로 65만이용해서 리스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8403e2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[165, 265, 365, 465, 565, 665, 765, 865, 965, 1065]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StudentID = []\n",
    "for i in range(1,11):\n",
    "    StudentID.append(int(str(i)+\"65\"))\n",
    "StudentID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f41aa",
   "metadata": {},
   "source": [
    "- 훈련 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81da370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  tom shifted gears . \n",
      "번역문 : tom a change de rapport . \n",
      "예측문 : tom a fait sa maison . \n",
      "\n",
      "\n",
      "원문 :  is he still here ? \n",
      "번역문 : est il encore ici ? \n",
      "예측문 : est il la voiture ? \n",
      "\n",
      "\n",
      "원문 :  i got a bad grade . \n",
      "번역문 : je me suis tape une mauvaise note . \n",
      "예측문 : j ai eu une journee . \n",
      "\n",
      "\n",
      "원문 :  how was work today ? \n",
      "번역문 : comment etait le travail aujourd hui ? \n",
      "예측문 : comment etait ce qu il en travail ? \n",
      "\n",
      "\n",
      "원문 :  i finally won . \n",
      "번역문 : j ai fini par l emporter . \n",
      "예측문 : j ai fini . \n",
      "\n",
      "\n",
      "원문 :  did you read them ? \n",
      "번역문 : les as tu lus ? \n",
      "예측문 : les avez vous les ? \n",
      "\n",
      "\n",
      "원문 :  take mine . \n",
      "번역문 : prenez la mienne . \n",
      "예측문 : prenez le mien . \n",
      "\n",
      "\n",
      "원문 :  this might hurt . \n",
      "번역문 : ca pourrait faire mal . \n",
      "예측문 : il peut etre fait de la tete . \n",
      "\n",
      "\n",
      "원문 :  they released tom . \n",
      "번역문 : ils ont relache tom . \n",
      "예측문 : ils ont tom . \n",
      "\n",
      "\n",
      "원문 :  tom looks deranged . \n",
      "번역문 : tom a l air perturbe . \n",
      "예측문 : tom a l air . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in StudentID:\n",
    "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "  print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
    "  print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
    "  print(\"예측문 :\",decoded_sentence[1:-5])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42432387",
   "metadata": {},
   "source": [
    "- 테스트 데이터에서 임의로 선택한 인덱스의 샘플의 결과출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91e79892",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  make an offer . \n",
      "번역문 : fais une offre . \n",
      "예측문 : fais une en train de tom ! \n",
      "\n",
      "\n",
      "원문 :  i ll sue you . \n",
      "번역문 : je te ferai un proces . \n",
      "예측문 : je vous ferai un te choix . \n",
      "\n",
      "\n",
      "원문 :  you are very rich . \n",
      "번역문 : vous etes tres riche . \n",
      "예측문 : vous etes tres riche . \n",
      "\n",
      "\n",
      "원문 :  tom just smiled . \n",
      "번역문 : tom venait de rire . \n",
      "예측문 : tom a presque l air fou . \n",
      "\n",
      "\n",
      "원문 :  come with us . \n",
      "번역문 : venez avec nous . \n",
      "예측문 : venez avec nous . \n",
      "\n",
      "\n",
      "원문 :  buy it . \n",
      "번역문 : achete la ! \n",
      "예측문 : faites le . \n",
      "\n",
      "\n",
      "원문 :  she is a beginner . \n",
      "번역문 : elle est novice . \n",
      "예측문 : elle est moi . \n",
      "\n",
      "\n",
      "원문 :  how much is that ? \n",
      "번역문 : combien cela coute t il ? \n",
      "예측문 : combien ca ? \n",
      "\n",
      "\n",
      "원문 :  that s a pencil . \n",
      "번역문 : c est un crayon . \n",
      "예측문 : c est un une raison . \n",
      "\n",
      "\n",
      "원문 :  is your mom home ? \n",
      "번역문 : ta mere est elle a la maison ? \n",
      "예측문 : est ce votre mere est elle chez elle ? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in StudentID:\n",
    "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "  print(\"원문 : \",seq2src(encoder_input_test[seq_index]))\n",
    "  print(\"번역문 :\",seq2tar(decoder_input_test[seq_index]))\n",
    "  print(\"예측문 :\",decoded_sentence[1:-5])\n",
    "  print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
